---
title: "Does Transparency in Moderation Really Matter?: User Behavior After Content Removal Explanations on Reddit"
date: 2019-06-11
research_type: 
- peer-reviewed-article
links:
- name: Preprint
  url: jhaver-2019-transparency.pdf
  icon: far fa-file-pdf
  local: true
- name: ACM DL
  url: https://doi.org/10.1145/3359252
  icon: ai ai-acmdl   
- name: Medium blog
  url: https://medium.com/acm-cscw/does-transparency-in-moderation-really-matter-b86bab9b4810
  icon: fab fa-medium  
- name: Slides
  url: jhaver-2019-transparency-slides.pdf
  icon: fab fa-slideshare
  local: true  
award:  
  status: Best Paper Award
  icon: fas fa-trophy
citation: >-
  **Shagun Jhaver**, [Amy Bruckman](https://www.cc.gatech.edu/fac/Amy.Bruckman/), and [Eric Gilbert](http://eegilbert.org), “Does Transparency in Moderation Really Matter?: User Behavior After Content Removal Explanations on Reddit,” *Proc. ACM Hum.-Comput. Interact. 3*, CSCW, Article 150 (November 2019), 27 pages. DOI: [`10.1145/3359252`](https://doi.org/10.1145/3359252) 
haiku: >-
  Transparency / Removal explanations / improve user behaviors.
---

## Important links

- [Paper (preprint)](jhaver-2019-transparency.pdf)
- [ACM Digital Library link](https://doi.org/10.1145/3359252)
- [Medium Blog that summarizes this paper](https://medium.com/acm-cscw/does-transparency-in-moderation-really-matter-b86bab9b4810)
- [Slides](jhaver-2019-transparency-slides.pdf)
- [Reddit discussion](https://www.reddit.com/r/science/comments/duwdco/should_moderators_provide_removal_explanations/) on this paper that hit the Reddit front page.
- [Hacker News discussion](https://news.ycombinator.com/item?id=21513871) on this paper that hit the site's front page.

## Media coverage
- ["Explaining why Reddit posts are removed helps people comply with rules,"](https://www.newscientist.com/article/2214308-explaining-why-reddit-posts-are-removed-helps-people-comply-with-rules/) *New Scientist*, August 25, 2019

## Abstract

When posts are removed on a social media platform, users may or may not receive an explanation. What kinds of explanations are provided? Do those explanations matter? Using a sample of 32 million Reddit posts, we characterize the removal explanations that are provided to Redditors, and link them to measures of subsequent user behaviors—including future post submissions and future post removals. Adopting a topic modeling approach, we show that removal explanations often provide information that educate users about the social norms of the community, thereby (theoretically) preparing them to become a productive member. We build regression models that show evidence of removal explanations playing a role in future user activity. Most importantly, we show that offering explanations for content moderation reduces the odds of future post removals. Additionally, explanations provided by human moderators did not have a significant advantage over explanations provided by bots for reducing future post removals. We propose design solutions that can promote the efficient use of explanation mechanisms, reflecting on how automated moderation tools can contribute to this space. Overall, our findings suggest that removal explanations may be under-utilized in moderation practices, and it is potentially worthwhile for community managers to invest time and resources into providing them.

## BibTeX citation

```bibtex
@article{Jhaver:2019Transparency,
    author = {Jhaver, Shagun and Bruckman, Amy and Gilbert, Eric},
    title = {Does Transparency in Moderation Really Matter?: User Behavior After Content Removal Explanations on Reddit},
    journal = {Proc. ACM Hum.-Comput. Interact.},
    year = {2019},
    issue_date = {November 2019},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {3},
    number = {CSCW},
    url = {https://doi.org/10.1145/3359252},
    doi = {10.1145/3359252},
    journal = {Proc. ACM Hum.-Comput. Interact.},
    month = nov,
    articleno = {150},
    numpages = {27}
    }
```
